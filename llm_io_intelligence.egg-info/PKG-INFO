Metadata-Version: 2.4
Name: llm-io-intelligence
Version: 0.1.0
Summary: Plugin for LLM adding support for io intelligence API models
Author: LLM IO Intelligence Plugin
License: Apache-2.0
Project-URL: Homepage, https://github.com/io-intelligence/llm-io-intelligence
Project-URL: Documentation, https://docs.io.net/reference/get-started-with-io-intelligence-api
Project-URL: Issues, https://github.com/io-intelligence/llm-io-intelligence/issues
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: llm>=0.9
Requires-Dist: httpx>=0.24.0
Requires-Dist: pydantic>=2.0.0

# LLM IO Intelligence Plugin

A plugin for [LLM](https://llm.datasette.io/) that provides access to IO Intelligence models with **full tool calling support**.

## Features

- **31 IO Intelligence models** including Llama, Qwen, DeepSeek, Gemma, and more
- **Complete tool calling support** - works with all LLM tools
- **Text-based tool call parsing** - innovative approach for models that simulate tool calls
- **Streaming and non-streaming support**
- **Vision model support** for image analysis
- **Embedding models** for text embeddings

## Installation

```bash
llm install llm-io-intelligence
```

## Setup

Set your IO Intelligence API key:

```bash
llm keys set iointelligence
# Paste your API key when prompted
```

Or set it as an environment variable:

```bash
export IOINTELLIGENCE_API_KEY="your-api-key-here"
```

## Tool Calling Support

This plugin provides **complete tool calling support** for IO Intelligence models. All LLM tools work seamlessly:

### Basic Tools

```bash
# Get LLM version
llm --tool llm_version "What version?" --td

# Get current time
llm --tool llm_time "What time is it?" --td
```

### Mathematical Tools

```bash
# Install math tools
llm install llm-tools-simpleeval

# Use mathematical calculations
llm --tool simple_eval "Calculate 15 * 23 + 7" --td
```

### Database Tools

```bash
# Install SQLite tools
llm install llm-tools-sqlite

# Query a database
llm -T 'SQLite("database.db")' "Show me all users" --td
```

### JavaScript Tools

```bash
# Install JavaScript tools
llm install llm-tools-quickjs

# Execute JavaScript code
llm --tool quickjs "Calculate factorial of 5" --td
```

## Available Models

### Chat Models

| Model ID | Full Name | Context Length |
|----------|-----------|----------------|
| `llama-3.3-70b` | meta-llama/Llama-3.3-70B-Instruct | 128K |
| `qwen3-235b` | Qwen/Qwen3-235B-A22B-FP8 | 8K |
| `deepseek-r1` | deepseek-ai/DeepSeek-R1 | 128K |
| `gemma-3-27b` | google/gemma-3-27b-it | 8K |
| `mistral-large-2411` | mistralai/Mistral-Large-Instruct-2411 | 128K |
| `phi-4` | microsoft/phi-4 | 16K |

*And 25 more models - see full list with `llm models list`*

### Vision Models

- `llama-3.2-90b-vision` - Image analysis and understanding
- `qwen2-vl-7b` - Vision-language model

### Embedding Models

- `bge-multilingual-gemma2` - Multilingual embeddings
- `mxbai-embed-large-v1` - Large context embeddings

## Usage Examples

### Basic Chat

```bash
llm -m llama-3.3-70b "Explain quantum computing"
```

### With Tools

```bash
# Mathematical calculation
llm -m llama-3.3-70b --tool simple_eval "What's the square root of 12345?" --td

# Database query
llm -m llama-3.3-70b -T 'SQLite("data.db")' "Show top 5 customers by revenue" --td
```

### Vision Analysis

```bash
llm -m llama-3.2-90b-vision "Describe this image" -a image.jpg
```

### Python API

```python
import llm
from llm_tools_sqlite import SQLite

# Get model
model = llm.get_model("llama-3.3-70b")

# Use with tools
response = model.prompt(
    "Show me all users with age > 25",
    tools=[SQLite("database.db")]
)

print(response.text())

# Check tool calls
for tool_call in response.tool_calls:
    print(f"Tool: {tool_call.name}, Args: {tool_call.arguments}")
```

## How Tool Calling Works

This plugin implements an innovative **text-based tool call parsing** approach:

1. **Tool definitions sent** - Proper OpenAI-compatible tool schemas sent to API
2. **Model outputs JSON** - Models output tool calls as JSON text like `{"name": "tool_name", "arguments": {}}`
3. **Text parsing** - Plugin detects and parses JSON patterns from model output
4. **Tool execution** - Converts text to actual `ToolCall` objects and executes them
5. **Results returned** - Tool results fed back to model for final response

This approach bridges the gap between IO Intelligence's text-based responses and LLM's tool calling framework.

## Tool Compatibility

✅ **Working Tools:**
- `llm_version`, `llm_time` - Built-in LLM tools
- `simple_eval` - Mathematical expressions
- `SQLite` - Database queries and schema inspection
- `quickjs` - JavaScript code execution
- `Datasette` - Remote database queries

✅ **All tool types supported:**
- Simple tools (no parameters)
- Parameterized tools (with arguments)
- Complex toolbox-style tools (multiple methods)
- Async and sync tools

## Configuration

### Model Options

```bash
# Set temperature
llm -m llama-3.3-70b -o temperature 0.8 "Creative writing task"

# Set max tokens
llm -m llama-3.3-70b -o max_tokens 1000 "Long explanation needed"

# Enable reasoning content (for compatible models)
llm -m deepseek-r1 -o reasoning_content true "Complex problem"
```

### Default Model

```bash
# Set default model
llm models default llama-3.3-70b

# Now you can omit -m
llm "Hello world"
```

## Development

### Running Tests

```bash
# Test basic functionality
python debug_tool_execution.py

# Test SQLite integration
python test_sqlite_real.py
```

### Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## Troubleshooting

### Tool Calling Issues

If tools aren't working:

1. **Check model support** - Use models like `llama-3.3-70b` that support tool calling
2. **Verify API key** - Ensure `IOINTELLIGENCE_API_KEY` is set correctly
3. **Use debug mode** - Add `--td` flag to see tool call details
4. **Check tool installation** - Ensure tool plugins are installed

### Common Errors

- `"does not support tools"` - Use a tool-compatible model
- `"API key not found"` - Set the `IOINTELLIGENCE_API_KEY` environment variable
- `"Chain limit exceeded"` - Model made too many tool calls (safety limit)

## License

Apache License 2.0

## Links

- [LLM Documentation](https://llm.datasette.io/)
- [IO Intelligence API](https://intelligence.io.solutions/)
- [Tool Plugins Directory](https://llm.datasette.io/en/stable/plugins/directory.html#tools)
- [Simon Willison's Tool Guide](https://simonwillison.net/2025/May/27/llm-tools/) 
